import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import HumanMessage, AIMessage

load_dotenv()

# 1. ê¸°ì–µì„ ë‹´ì„ ë¦¬ìŠ¤íŠ¸ (ì´ê²Œ AIì˜ ë‡Œì…ë‹ˆë‹¤)
chat_history = []

# 2. í…œí”Œë¦¿ì— 'ì´ì „ ëŒ€í™” ë‚´ìš©' ìë¦¬ë¥¼ ë§Œë“¤ì–´ì¤ë‹ˆë‹¤ (history ë¶€ë¶„)
template = ChatPromptTemplate.from_messages([
    ("system", "ë„ˆëŠ” 5ì„±ê¸‰ í˜¸í…”ì˜ ìš”ë¦¬ì‚¬ì•¼. ì§ˆë¬¸ì„ ë°›ìœ¼ë©´ í•„ìš”í•œ ì¬ë£Œë¥¼ 'ì¥ë°”êµ¬ë‹ˆ ë¦¬ìŠ¤íŠ¸' í˜•ì‹ìœ¼ë¡œ ë¨¼ì € ë³´ì—¬ì£¼ê³  ì¡°ë¦¬ë²•ì„ ì„¤ëª…í•´ì¤˜."),
    MessagesPlaceholder(variable_name="history"), # ì—¬ê¸°ì— ì´ì „ ëŒ€í™”ê°€ ë“¤ì–´ê°
    ("user", "{question}")
])

chat = ChatOpenAI(model="gpt-3.5-turbo")

print("=== ğŸ§  ê¸°ì–µë ¥ì´ ìƒê¸´ ìš”ë¦¬ì‚¬ ì±—ë´‡ ===")

while True:
    user_q = input("ì§ˆë¬¸: ")
    if user_q == "ê·¸ë§Œ": break
    
    # 3. í…œí”Œë¦¿ì— í˜„ì¬ ì§ˆë¬¸ê³¼ ì´ì „ ëŒ€í™” ë‚´ì—­(history)ì„ í•¨ê»˜ ì „ë‹¬
    final_prompt = template.invoke({"history": chat_history, "question": user_q})
    
    response = chat.invoke(final_prompt)
    
    # 4. ëŒ€í™” ë‚´ì—­ ì—…ë°ì´íŠ¸ (ë‚˜ì˜ ì§ˆë¬¸ê³¼ AIì˜ ë‹µë³€ì„ ì €ì¥)
    chat_history.append(HumanMessage(content=user_q))
    chat_history.append(AIMessage(content=response.content))
    
    print(f"ğŸ¤– [ìš”ë¦¬ì‚¬ AI]:\n{response.content}\n")