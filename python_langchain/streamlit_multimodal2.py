"""
ë©€í‹°ëª¨ë‹¬ RAG ì˜ˆì œ
í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, PDF ë“± ë‹¤ì–‘í•œ í˜•ì‹ì˜ ë°ì´í„°ë¥¼ ì²˜ë¦¬

ì£¼ìš” ê¸°ëŠ¥:
1. í…ìŠ¤íŠ¸ íŒŒì¼ (.txt) ë¡œë“œ ë° ì²˜ë¦¬
2. ì´ë¯¸ì§€ íŒŒì¼ (.jpg, .png ë“±) GPT-4 Vision APIë¡œ ë¶„ì„
3. PDF íŒŒì¼ (.pdf) í…ìŠ¤íŠ¸ ì¶”ì¶œ
4. ëª¨ë“  ë¬¸ì„œë¥¼ ë²¡í„° ì„ë² ë”©í•˜ì—¬ Pineconeì— ì €ì¥
5. í†µí•© ê²€ìƒ‰ ë° ì§ˆì˜ì‘ë‹µ
"""

# í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜
# pip install Pillow  # ì´ë¯¸ì§€ ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ (ì—´ê¸°/í¬ê¸°ì¡°ì ˆ/í¬ë§·ë³€í™˜/base64ì¸ì½”ë”©)
# pip install langchain langchain-openai langchain-pinecone langchain-community
# pip install pinecone-client python-dotenv

import os
from pathlib import Path
from dotenv import load_dotenv

# LangChain í•µì‹¬ ì»´í¬ë„ŒíŠ¸
from langchain_text_splitters import RecursiveCharacterTextSplitter  # ë¬¸ì„œ ë¶„í• 
from langchain_openai import OpenAIEmbeddings, ChatOpenAI  # OpenAI ì„ë² ë”© ë° LLM
from langchain_pinecone import PineconeVectorStore  # Pinecone ë²¡í„°ìŠ¤í† ì–´

# ë¬¸ì„œ ë¡œë”
from langchain_community.document_loaders import (
    TextLoader,  # í…ìŠ¤íŠ¸ íŒŒì¼ ë¡œë”
    UnstructuredImageLoader,  # ì´ë¯¸ì§€ ë¡œë” (ë¯¸ì‚¬ìš©)
    PyPDFLoader,  # PDF ë¡œë”
    DirectoryLoader  # ë””ë ‰í† ë¦¬ ì „ì²´ ë¡œë“œ
)

# LangChain ì²´ì¸ êµ¬ì„± ìš”ì†Œ
from langchain_core.prompts import ChatPromptTemplate  # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
from langchain_core.runnables import RunnablePassthrough  # ì²´ì¸ ì—°ê²°
from langchain_core.output_parsers import StrOutputParser  # ì¶œë ¥ íŒŒì‹±
from langchain_core.documents import Document  # ë¬¸ì„œ ê°ì²´
from langchain_core.messages import HumanMessage  # Vision APIìš© ë©”ì‹œì§€

# Pinecone ë° ì´ë¯¸ì§€ ì²˜ë¦¬
from pinecone import Pinecone, ServerlessSpec  # Pinecone í´ë¼ì´ì–¸íŠ¸
from PIL import Image  # ì´ë¯¸ì§€ ì²˜ë¦¬ (ë¦¬ì‚¬ì´ì§•, í¬ë§· ë³€í™˜)
import base64  # ì´ë¯¸ì§€ base64 ì¸ì½”ë”©
from io import BytesIO  # ë©”ëª¨ë¦¬ ë²„í¼

# =================================================================
# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (.env íŒŒì¼ì—ì„œ API í‚¤ ì½ê¸°)
# =================================================================
load_dotenv()

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")  # OpenAI API í‚¤
PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")  # Pinecone API í‚¤
PINECONE_ENVIRONMENT = os.getenv("PINECONE_ENVIRONMENT")  # Pinecone ë¦¬ì „ (ì˜ˆ: us-east-1)
PINECONE_INDEX_NAME = os.getenv("PINECONE_INDEX_NAME", "restaurant-multimodal")  # ì¸ë±ìŠ¤ ì´ë¦„


# =================================================================
# ë©€í‹°ëª¨ë‹¬ ë¬¸ì„œ ë¡œë” í´ë˜ìŠ¤
# =================================================================
class MultiModalDocumentLoader:
    """
    ë‹¤ì–‘í•œ í˜•ì‹ì˜ ë¬¸ì„œë¥¼ ë¡œë“œí•˜ëŠ” í´ë˜ìŠ¤
    
    ì§€ì› í˜•ì‹:
    - í…ìŠ¤íŠ¸ íŒŒì¼ (.txt): DirectoryLoaderë¡œ ì¼ê´„ ë¡œë“œ
    - ì´ë¯¸ì§€ íŒŒì¼ (.jpg, .png, .gif, .bmp): GPT-4 Vision APIë¡œ ë¶„ì„
    - PDF íŒŒì¼ (.pdf): PyPDFLoaderë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
    
    Attributes:
        data_directory (str): ë¬¸ì„œê°€ ì €ì¥ëœ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        documents (list): ë¡œë“œëœ Document ê°ì²´ ë¦¬ìŠ¤íŠ¸
    """
    
    def __init__(self, data_directory):
        """ì´ˆê¸°í™” ë©”ì„œë“œ"""
        self.data_directory = data_directory  # ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œ
        self.documents = []  # ë¡œë“œëœ ë¬¸ì„œ ì €ì¥ ë¦¬ìŠ¤íŠ¸
    
    def load_text_files(self):
        """
        í…ìŠ¤íŠ¸ íŒŒì¼ ë¡œë“œ
        
        - DirectoryLoaderë¡œ data í´ë” ë‚´ ëª¨ë“  .txt íŒŒì¼ ê²€ìƒ‰
        - UTF-8 ì¸ì½”ë”©ìœ¼ë¡œ í…ìŠ¤íŠ¸ ì½ê¸°
        - ë©”íƒ€ë°ì´í„°ì— íƒ€ì…('text') ë° íŒŒì¼ëª… ì¶”ê°€
        
        Returns:
            list: ë¡œë“œëœ Document ê°ì²´ ë¦¬ìŠ¤íŠ¸
        """
        print("ğŸ“„ í…ìŠ¤íŠ¸ íŒŒì¼ ë¡œë“œ ì¤‘...")
        
        # DirectoryLoader: ë””ë ‰í† ë¦¬ ë‚´ íŠ¹ì • íŒ¨í„´ íŒŒì¼ ì¼ê´„ ë¡œë“œ
        loader = DirectoryLoader(
            self.data_directory,
            glob="**/*.txt",  # ëª¨ë“  í•˜ìœ„ í´ë”ì˜ .txt íŒŒì¼
            loader_cls=TextLoader,  # í…ìŠ¤íŠ¸ ë¡œë” ì‚¬ìš©
            loader_kwargs={"encoding": "utf-8"}  # UTF-8 ì¸ì½”ë”©
        )
        docs = loader.load()
        
        # ê° ë¬¸ì„œì— ë©”íƒ€ë°ì´í„° ì¶”ê°€
        for doc in docs:
            doc.metadata['type'] = 'text'  # ë¬¸ì„œ íƒ€ì… ì§€ì •
            doc.metadata['source'] = os.path.basename(doc.metadata['source'])  # íŒŒì¼ëª…ë§Œ ì¶”ì¶œ
        
        self.documents.extend(docs)  # ì „ì²´ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
        print(f"âœ“ í…ìŠ¤íŠ¸ íŒŒì¼ {len(docs)}ê°œ ë¡œë“œ ì™„ë£Œ")
        return docs
    
    def load_pdf_files(self):
        """
        PDF íŒŒì¼ ë¡œë“œ
        
        - PyPDFLoaderë¡œ PDF íŒŒì¼ì˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        - ê° í˜ì´ì§€ê°€ ë³„ë„ Documentë¡œ ìƒì„±ë¨
        - ë©”íƒ€ë°ì´í„°ì— íƒ€ì…('pdf') ë° íŒŒì¼ëª… ì¶”ê°€
        
        Returns:
            list: ë¡œë“œëœ Document ê°ì²´ ë¦¬ìŠ¤íŠ¸ (í˜ì´ì§€ ë‹¨ìœ„)
        """
        print("ğŸ“‘ PDF íŒŒì¼ ë¡œë“œ ì¤‘...")
        
        # data í´ë” ë‚´ ëª¨ë“  .pdf íŒŒì¼ ê²€ìƒ‰
        pdf_files = list(Path(self.data_directory).glob("**/*.pdf"))
        docs = []
        
        # ê° PDF íŒŒì¼ ì²˜ë¦¬
        for pdf_file in pdf_files:
            try:
                loader = PyPDFLoader(str(pdf_file))  # PDF ë¡œë” ìƒì„±
                pdf_docs = loader.load()  # PDF í˜ì´ì§€ë³„ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                
                # ê° í˜ì´ì§€ì— ë©”íƒ€ë°ì´í„° ì¶”ê°€
                for doc in pdf_docs:
                    doc.metadata['type'] = 'pdf'  # ë¬¸ì„œ íƒ€ì… ì§€ì •
                    doc.metadata['source'] = pdf_file.name  # íŒŒì¼ëª…
                
                docs.extend(pdf_docs)  # ì „ì²´ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
                print(f"âœ“ PDF ë¡œë“œ: {pdf_file.name}")
            except Exception as e:
                print(f"âœ— PDF ë¡œë“œ ì‹¤íŒ¨: {pdf_file.name} - {e}")
        
        self.documents.extend(docs)
        print(f"âœ“ PDF íŒŒì¼ {len(docs)}í˜ì´ì§€ ë¡œë“œ ì™„ë£Œ")
        return docs
    
    def load_image_files(self):
        """
        ì´ë¯¸ì§€ íŒŒì¼ ë¡œë“œ ë° Vision APIë¡œ ë¶„ì„
        
        - ì§€ì› í˜•ì‹: .jpg, .jpeg, .png, .gif, .bmp
        - GPT-4 Vision APIë¡œ ì´ë¯¸ì§€ ë‚´ìš© ë¶„ì„ (ë©”ë‰´, ê°€ê²©, ì¬ë£Œ ë“± ì¶”ì¶œ)
        - ë¶„ì„ ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ Document ìƒì„±
        
        Returns:
            list: Vision API ë¶„ì„ ê²°ê³¼ê°€ ë‹´ê¸´ Document ê°ì²´ ë¦¬ìŠ¤íŠ¸
        """
        print("ğŸ–¼ï¸  ì´ë¯¸ì§€ íŒŒì¼ ë¡œë“œ ì¤‘...")
        
        # ì§€ì›í•˜ëŠ” ì´ë¯¸ì§€ í™•ì¥ì ëª©ë¡
        image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.gif', '*.bmp']
        image_files = []
        
        # ê° í™•ì¥ìë³„ë¡œ íŒŒì¼ ê²€ìƒ‰
        for ext in image_extensions:
            image_files.extend(Path(self.data_directory).glob(f"**/{ext}"))
        
        docs = []
        # ê° ì´ë¯¸ì§€ íŒŒì¼ ì²˜ë¦¬
        for img_file in image_files:
            try:
                # GPT-4 Vision APIë¡œ ì´ë¯¸ì§€ ë¶„ì„ â†’ í…ìŠ¤íŠ¸ ì„¤ëª… ìƒì„±
                doc = self._process_image_with_vision(img_file)
                if doc:
                    docs.append(doc)
                    print(f"âœ“ ì´ë¯¸ì§€ ì²˜ë¦¬: {img_file.name}")
            except Exception as e:
                print(f"âœ— ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {img_file.name} - {e}")
        
        self.documents.extend(docs)  # ì „ì²´ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
        print(f"âœ“ ì´ë¯¸ì§€ íŒŒì¼ {len(docs)}ê°œ ì²˜ë¦¬ ì™„ë£Œ")
        return docs
    
    def _process_image_with_vision(self, image_path):
        """
        GPT-4 Vision APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ë‚´ìš© ë¶„ì„
        
        í”„ë¡œì„¸ìŠ¤:
        1. ì´ë¯¸ì§€ë¥¼ PILë¡œ ì—´ê¸°
        2. í¬ê¸° ì¡°ì ˆ (800x800 ìµœëŒ€, ë¹„ìš© ì ˆê° ëª©ì )
        3. PNG í¬ë§·ìœ¼ë¡œ ë³€í™˜
        4. base64 ì¸ì½”ë”© (Vision API ì „ì†¡ìš©)
        5. GPT-4 Vision API í˜¸ì¶œ (ì´ë¯¸ì§€ + í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸)
        6. ë¶„ì„ ê²°ê³¼ë¥¼ Document ê°ì²´ë¡œ ë°˜í™˜
        
        Args:
            image_path (Path): ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            Document: ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ê°€ ë‹´ê¸´ Document ê°ì²´
            None: ì²˜ë¦¬ ì‹¤íŒ¨ ì‹œ
        """
        try:
            # ========== Step 1: ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”© ==========
            with Image.open(image_path) as img:
                # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì ˆ (ë¹„ìš© ì ˆê° + ì†ë„ í–¥ìƒ)
                # ìµœëŒ€ 800x800 í”½ì…€, ë¹„ìœ¨ ìœ ì§€
                img.thumbnail((800, 800))
                
                # ë©”ëª¨ë¦¬ ë²„í¼ì— PNG í¬ë§·ìœ¼ë¡œ ì €ì¥
                buffered = BytesIO()
                img.save(buffered, format="PNG")
                
                # base64 ì¸ì½”ë”© (Vision API ì „ì†¡ í˜•ì‹)
                img_str = base64.b64encode(buffered.getvalue()).decode('utf-8')
            
            # ========== Step 2: GPT-4 Vision API ì„¤ì • ==========
            llm = ChatOpenAI(
                model="gpt-4o-mini",  # Vision ì§€ì› ëª¨ë¸
                # max_tokens=500  # ìµœëŒ€ ì‘ë‹µ ê¸¸ì´
            )
            
            # ========== Step 3: Vision API í˜¸ì¶œ ë©”ì‹œì§€ êµ¬ì„± ==========
            # HumanMessage: í…ìŠ¤íŠ¸ + ì´ë¯¸ì§€ ë™ì‹œ ì „ì†¡ ê°€ëŠ¥
            message = HumanMessage(
                content=[
                    {
                        "type": "text",
                        "text": """ì´ ì´ë¯¸ì§€ë¥¼ ìì„¸íˆ ë¶„ì„í•´ì£¼ì„¸ìš”.
ë§Œì•½ ë ˆìŠ¤í† ë‘ ë©”ë‰´ë‚˜ ìŒì‹ ì‚¬ì§„ì´ë¼ë©´:
- ë©”ë‰´ ì´ë¦„
- ê°€ê²© (ìˆë‹¤ë©´)
- ì¬ë£Œë‚˜ ì„¤ëª…
- ê¸°íƒ€ íŠ¹ì§•

ë§Œì•½ ì™€ì¸ì´ë‚˜ ìŒë£Œë¼ë©´:
- ì œí’ˆëª…
- ì¢…ë¥˜/í’ˆì¢…
- ê°€ê²© (ìˆë‹¤ë©´)
- íŠ¹ì§•

ì¼ë°˜ ì´ë¯¸ì§€ë¼ë©´ ì£¼ìš” ë‚´ìš©ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”."""
                    },
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/png;base64,{img_str}"  # base64 ì¸ì½”ë”©ëœ ì´ë¯¸ì§€
                        }
                    }
                ]
            )
            
            # ========== Step 4: Vision API ì‹¤í–‰ ==========
            response = llm.invoke([message])  # GPT-4 Vision í˜¸ì¶œ
            description = response.content  # ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ í…ìŠ¤íŠ¸
            
            # ========== Step 5: Document ê°ì²´ ìƒì„± ==========
            doc = Document(
                page_content=f"[ì´ë¯¸ì§€: {image_path.name}]\n{description}",  # ë¶„ì„ ê²°ê³¼ ì €ì¥
                metadata={
                    'type': 'image',  # ë¬¸ì„œ íƒ€ì…
                    'source': image_path.name,  # íŒŒì¼ëª…
                    'image_path': str(image_path)  # ì›ë³¸ ì´ë¯¸ì§€ ê²½ë¡œ (UI í‘œì‹œìš©)
                }
            )
            
            return doc
            
        except Exception as e:
            print(f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return None
    
    def load_all(self):
        """ëª¨ë“  í˜•ì‹ì˜ íŒŒì¼ ë¡œë“œ"""
        print("\n" + "="*60)
        print("ë©€í‹°ëª¨ë‹¬ ë¬¸ì„œ ë¡œë“œ ì‹œì‘")
        print("="*60 + "\n")
        
        self.load_text_files()
        # self.load_pdf_files() #ë ˆìŠ¤í† ë‘ì—ëŠ” pdfíŒŒì¼ ì—†ìŒ
        self.load_image_files()
        
        print(f"\nâœ“ ì´ {len(self.documents)}ê°œ ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ")
        print(f"   - í…ìŠ¤íŠ¸: {sum(1 for d in self.documents if d.metadata.get('type') == 'text')}ê°œ")
        print(f"   - PDF: {sum(1 for d in self.documents if d.metadata.get('type') == 'pdf')}ê°œ")
        print(f"   - ì´ë¯¸ì§€: {sum(1 for d in self.documents if d.metadata.get('type') == 'image')}ê°œ\n")
        
        return self.documents


# =================================================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
# =================================================================

def split_documents(documents, chunk_size=500, chunk_overlap=50):
    """
    ë¬¸ì„œë¥¼ ì‘ì€ ì²­í¬ë¡œ ë¶„í• 
    
    - RecursiveCharacterTextSplitter: ë¬¸ë‹¨, ë¬¸ì¥, ë‹¨ì–´ ë‹¨ìœ„ë¡œ ì¬ê·€ì  ë¶„í• 
    - chunk_size: ê° ì²­í¬ì˜ ìµœëŒ€ ê¸¸ì´ (ë¬¸ì ìˆ˜)
    - chunk_overlap: ì¸ì ‘ ì²­í¬ ê°„ ê²¹ì¹˜ëŠ” ë¶€ë¶„ (ë¬¸ë§¥ ìœ ì§€)
    
    Args:
        documents (list): ë¶„í• í•  Document ê°ì²´ ë¦¬ìŠ¤íŠ¸
        chunk_size (int): ì²­í¬ ìµœëŒ€ í¬ê¸° (default: 500)
        chunk_overlap (int): ì²­í¬ ê°„ ê²¹ì¹¨ (default: 50)
        
    Returns:
        list: ë¶„í• ëœ Document ì²­í¬ ë¦¬ìŠ¤íŠ¸
    """
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_size,  # ì²­í¬ ìµœëŒ€ ê¸¸ì´
        chunk_overlap=chunk_overlap,  # ê²¹ì¹¨ëŠ” ë¬¸ì ìˆ˜
        length_function=len,  # ê¸¸ì´ ê³„ì‚° í•¨ìˆ˜
    )
    
    splits = text_splitter.split_documents(documents)  # ë¶„í•  ì‹¤í–‰
    print(f"âœ“ ë¬¸ì„œ ë¶„í•  ì™„ë£Œ: {len(splits)}ê°œ ì²­í¬ ìƒì„±")
    
    return splits


def initialize_pinecone():
    """
    Pinecone ì´ˆê¸°í™” ë° ì¸ë±ìŠ¤ ìƒì„±
    
    - Pinecone í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    - ì¸ë±ìŠ¤ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    - ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„± (1536ì°¨ì›, cosine ìœ ì‚¬ë„, AWS serverless)
    
    Returns:
        Pinecone: Pinecone í´ë¼ì´ì–¸íŠ¸ ê°ì²´
    """
    pc = Pinecone(api_key=PINECONE_API_KEY)  # Pinecone í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    existing_indexes = [index.name for index in pc.list_indexes()]  # ê¸°ì¡´ ì¸ë±ìŠ¤ ëª©ë¡
    
    # ì¸ë±ìŠ¤ê°€ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
    if PINECONE_INDEX_NAME not in existing_indexes:
        print(f"ìƒˆë¡œìš´ ì¸ë±ìŠ¤ ìƒì„±: {PINECONE_INDEX_NAME}")
        pc.create_index(
            name=PINECONE_INDEX_NAME,  # ì¸ë±ìŠ¤ ì´ë¦„
            dimension=1536,  # OpenAI text-embedding-3-small ì°¨ì›
            metric='cosine',  # ìœ ì‚¬ë„ ê³„ì‚° ë°©ì‹ (cosine similarity)
            spec=ServerlessSpec(
                cloud='aws',  # í´ë¼ìš°ë“œ í”„ë¡œë°”ì´ë”
                region='us-east-1'  # ë¦¬ì „ (us-east-1 ë“±)
            )
        )
        print(f"âœ“ ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ")
    else:
        print(f"âœ“ ê¸°ì¡´ ì¸ë±ìŠ¤ ì‚¬ìš©: {PINECONE_INDEX_NAME}")
    
    return pc


def create_or_load_vectorstore(documents=None, force_recreate=False):
    """
    Pinecone ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ë˜ëŠ” ë¡œë“œ
    
    ì‘ë™ ë°©ì‹:
    1. force_recreate=False & ë²¡í„° ì¡´ì¬ â†’ ê¸°ì¡´ ë²¡í„° ë¡œë“œ (ë¹„ìš© ì ˆê°)
    2. force_recreate=True â†’ ê¸°ì¡´ ë²¡í„° ì‚­ì œ í›„ ìƒˆë¡œ ìƒì„±
    3. ë²¡í„° ì—†ìŒ â†’ ìƒˆë¡œ ìƒì„±
    
    í”„ë¡œì„¸ìŠ¤:
    - ë¬¸ì„œ í…ìŠ¤íŠ¸ â†’ OpenAI Embeddings (1536ì°¨ì› ë²¡í„°)
    - ë²¡í„° â†’ Pinecone ì €ì¥
    - ë©”íƒ€ë°ì´í„°(íƒ€ì…, ì†ŒìŠ¤, ê²½ë¡œ) í¬í•¨
    
    Args:
        documents (list): ì„ë² ë”©í•  ë¬¸ì„œ (ìƒˆë¡œ ìƒì„± ì‹œ í•„ìš”)
        force_recreate (bool): Trueë©´ ê¸°ì¡´ ë°ì´í„° ì‚­ì œí•˜ê³  ìƒˆë¡œ ìƒì„±
        
    Returns:
        PineconeVectorStore: Pinecone ë²¡í„°ìŠ¤í† ì–´ ê°ì²´
    """
    # OpenAI Embeddings ëª¨ë¸ ì„¤ì •
    embeddings = OpenAIEmbeddings(
        openai_api_key=OPENAI_API_KEY,
        model="text-embedding-3-small",  # ì„ë² ë”© ëª¨ë¸
        dimensions=1536  # ë²¡í„° ì°¨ì›
    )
    
    # Pinecone ì¸ë±ìŠ¤ ì—°ê²°
    pc = Pinecone(api_key=PINECONE_API_KEY)
    index = pc.Index(PINECONE_INDEX_NAME)
    
    # ========== ì¸ë±ìŠ¤ ìƒíƒœ í™•ì¸ ==========
    stats = index.describe_index_stats()  # ì¸ë±ìŠ¤ í†µê³„
    vector_count = stats.get('total_vector_count', 0)  # ì €ì¥ëœ ë²¡í„° ê°œìˆ˜
    
    # ========== ê¸°ì¡´ ë°ì´í„°ê°€ ìˆê³  ì¬ìƒì„± í”Œë˜ê·¸ê°€ ì—†ìœ¼ë©´ ë¡œë“œ ==========
    if vector_count > 0 and not force_recreate:
        print(f"âœ“ ê¸°ì¡´ ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ (ë²¡í„° ìˆ˜: {vector_count})")
        vectorstore = PineconeVectorStore(
            index=index,  # Pinecone ì¸ë±ìŠ¤
            embedding=embeddings,  # ì„ë² ë”© ëª¨ë¸
            text_key="text"  # í…ìŠ¤íŠ¸ í•„ë“œ í‚¤
        )
    else:
        # ========== ë°ì´í„°ê°€ ì—†ê±°ë‚˜ ì¬ìƒì„± ìš”ì²­ ì‹œ ==========
        if force_recreate and vector_count > 0:
            print(f"ê¸°ì¡´ ë°ì´í„° ì‚­ì œ ì¤‘... (ë²¡í„° ìˆ˜: {vector_count})")
            index.delete(delete_all=True)  # ëª¨ë“  ë²¡í„° ì‚­ì œ
        
        if documents is None:
            raise ValueError("ìƒˆë¡œ ìƒì„±í•˜ë ¤ë©´ documents íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤")
        
        # ì„ë² ë”© ìƒì„± ë° Pinecone ì—…ë¡œë“œ
        print(f"ì„ë² ë”© ìƒì„± ë° Pinecone ì—…ë¡œë“œ ì¤‘... ({len(documents)}ê°œ ë¬¸ì„œ)")
        vectorstore = PineconeVectorStore.from_documents(
            documents=documents,  # ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
            embedding=embeddings,  # ì„ë² ë”© ëª¨ë¸
            index_name=PINECONE_INDEX_NAME  # ì¸ë±ìŠ¤ ì´ë¦„
        )
        print(f"âœ“ {len(documents)}ê°œ ë¬¸ì„œ ì„ë² ë”© ì™„ë£Œ ë° Pineconeì— ì €ì¥")
    
    return vectorstore


def create_multimodal_rag_chain(vectorstore):
    """ë©€í‹°ëª¨ë‹¬ RAG ì²´ì¸ ìƒì„±"""
    llm = ChatOpenAI(
        openai_api_key=OPENAI_API_KEY,
        model_name="gpt-4o-mini",
        temperature=0
    )
    
    retriever = vectorstore.as_retriever(
        search_type="similarity",
        search_kwargs={"k": 5}  # ë” ë§ì€ ë¬¸ì„œ ê²€ìƒ‰
    )
    
    template = """ë‹¹ì‹ ì€ ë ˆìŠ¤í† ë‘ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ë„ìš°ë¯¸ì…ë‹ˆë‹¤.
ë‹¤ì–‘í•œ í˜•ì‹ì˜ ë¬¸ì„œ(í…ìŠ¤íŠ¸, PDF, ì´ë¯¸ì§€)ì—ì„œ ì •ë³´ë¥¼ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.
ê° ë¬¸ì„œì˜ ì¶œì²˜ íƒ€ì…ì„ ê³ ë ¤í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”.

ì»¨í…ìŠ¤íŠ¸:
{context}

ì§ˆë¬¸: {question}

ë‹µë³€:"""

    prompt = ChatPromptTemplate.from_template(template)
    
    def format_docs(docs):
        formatted = []
        for doc in docs:
            doc_type = doc.metadata.get('type', 'unknown')
            source = doc.metadata.get('source', 'Unknown')
            formatted.append(f"[{doc_type.upper()} - {source}]\n{doc.page_content}")
        return "\n\n".join(formatted)
    
    rag_chain = (
        {"context": retriever | format_docs, "question": RunnablePassthrough()}
        | prompt
        | llm
        | StrOutputParser()
    )
    
    print("âœ“ ë©€í‹°ëª¨ë‹¬ RAG ì²´ì¸ ìƒì„± ì™„ë£Œ")
    
    return rag_chain, retriever


def search_and_answer(rag_chain, retriever, query):
    """ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„± (ë¬¸ì„œ íƒ€ì… í‘œì‹œ)"""
    print(f"\n{'='*60}")
    print(f"ì§ˆë¬¸: {query}")
    print(f"{'='*60}")
    
    answer = rag_chain.invoke(query)
    print(f"\në‹µë³€:\n{answer}")
    
    source_docs = retriever.invoke(query)
    print(f"\n{'='*60}")
    print("ì°¸ì¡° ë¬¸ì„œ (ë©€í‹°ëª¨ë‹¬):")
    for i, doc in enumerate(source_docs, 1):
        doc_type = doc.metadata.get('type', 'unknown')
        source = doc.metadata.get('source', 'Unknown')
        icon = {'text': 'ğŸ“„', 'pdf': 'ğŸ“‘', 'image': 'ğŸ–¼ï¸'}.get(doc_type, 'ğŸ“')
        
        print(f"\n[{i}] {icon} {doc_type.upper()} - {source}")
        print(f"    ë‚´ìš©: {doc.page_content[:150]}...")
    
    print(f"{'='*60}\n")
    
    return answer


def analyze_document_types(documents):
    """ë¬¸ì„œ íƒ€ì…ë³„ í†µê³„"""
    print("\n" + "="*60)
    print("ë¬¸ì„œ íƒ€ì… ë¶„ì„")
    print("="*60 + "\n")
    
    types = {}
    for doc in documents:
        doc_type = doc.metadata.get('type', 'unknown')
        types[doc_type] = types.get(doc_type, 0) + 1
    
    for doc_type, count in types.items():
        icon = {'text': 'ğŸ“„', 'pdf': 'ğŸ“‘', 'image': 'ğŸ–¼ï¸'}.get(doc_type, 'ğŸ“')
        print(f"{icon} {doc_type.upper()}: {count}ê°œ")
    
    print()


# =================================================================
# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# =================================================================

def main():
    """
    ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
    
    ì‹¤í–‰ ë‹¨ê³„:
    1. ë©€í‹°ëª¨ë‹¬ ë¬¸ì„œ ë¡œë“œ (í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, PDF)
    2. ë¬¸ì„œ ë¶„í•  (chunk ë‹¨ìœ„)
    3. Pinecone ì´ˆê¸°í™”
    4. ë²¡í„°ìŠ¤í† ì–´ ìƒì„±/ë¡œë“œ
    5. RAG ì²´ì¸ ìƒì„±
    6. ì˜ˆì œ ì§ˆë¬¸ ì‹¤í–‰
    7. ëŒ€í™”í˜• ëª¨ë“œ ì§„ì…
    """
    print("\n" + "="*60)
    print("ë©€í‹°ëª¨ë‹¬ RAG ì˜ˆì œ")
    print("="*60 + "\n")
    
    # ========== 1ë‹¨ê³„: ë©€í‹°ëª¨ë‹¬ ë¬¸ì„œ ë¡œë“œ ==========
    print("1ë‹¨ê³„: ë©€í‹°ëª¨ë‹¬ ë¬¸ì„œ ë¡œë“œ")
    data_directory = os.path.join(os.path.dirname(__file__), 'data')  # data í´ë” ê²½ë¡œ
    
    loader = MultiModalDocumentLoader(data_directory)  # ë¡œë” ìƒì„±
    documents = loader.load_all()  # ëª¨ë“  í˜•ì‹ íŒŒì¼ ë¡œë“œ
    
    # ë¬¸ì„œê°€ ì—†ìœ¼ë©´ ì¢…ë£Œ
    if not documents:
        print("âŒ ë¡œë“œëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. data í´ë”ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        return
    
    # ë¬¸ì„œ íƒ€ì…ë³„ í†µê³„ í‘œì‹œ
    analyze_document_types(documents)
    
    # ========== 2ë‹¨ê³„: ë¬¸ì„œ ë¶„í•  ==========
    print("\n2ë‹¨ê³„: ë¬¸ì„œ ë¶„í• ")
    splits = split_documents(documents)  # ë¬¸ì„œë¥¼ ì²­í¬ë¡œ ë¶„í• 
    
    # ========== 3ë‹¨ê³„: Pinecone ì´ˆê¸°í™” ==========
    print("\n3ë‹¨ê³„: Pinecone ì´ˆê¸°í™”")
    initialize_pinecone()  # Pinecone ì¸ë±ìŠ¤ ìƒì„± ë˜ëŠ” í™•ì¸
    
    # ========== 4ë‹¨ê³„: ë²¡í„°ìŠ¤í† ì–´ ìƒì„±/ë¡œë“œ ==========
    print("\n4ë‹¨ê³„: ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ/ìƒì„±")
    # ì£¼ì˜: force_recreate=Trueë¡œ ì„¤ì •í•˜ë©´ ê¸°ì¡´ ë°ì´í„° ì‚­ì œ í›„ ì¬ìƒì„± 
    # (Vision API ë¹„ìš© ë°œìƒ)
    # ì´í›„ ì‹¤í–‰ ì‹œì—ëŠ” force_recreate=Falseë¡œ ë³€ê²½ ê¶Œì¥
    vectorstore = create_or_load_vectorstore(documents=splits, force_recreate=False)
    
    # ========== 5ë‹¨ê³„: ë©€í‹°ëª¨ë‹¬ RAG ì²´ì¸ ìƒì„± ==========
    print("\n5ë‹¨ê³„: ë©€í‹°ëª¨ë‹¬ RAG ì²´ì¸ ìƒì„±")
    rag_chain, retriever = create_multimodal_rag_chain(vectorstore)
    
    # ========== 6ë‹¨ê³„: ì§ˆë¬¸ ì˜ˆì œ ==========
    print("\n6ë‹¨ê³„: ë©€í‹°ëª¨ë‹¬ ê²€ìƒ‰ ì˜ˆì œ")
    
    example_queries = [
        "ë©”ë‰´ì— ëŒ€í•œ ëª¨ë“  ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”",
        "ì´ë¯¸ì§€ì—ì„œ ì°¾ì„ ìˆ˜ ìˆëŠ” ì •ë³´ê°€ ìˆë‚˜ìš”?",
        "PDF ë¬¸ì„œì—ëŠ” ì–´ë–¤ ë‚´ìš©ì´ ìˆë‚˜ìš”?",
    ]
    
    for query in example_queries:
        search_and_answer(rag_chain, retriever, query)
    
    # ========== 7ë‹¨ê³„: ëŒ€í™”í˜• ëª¨ë“œ ==========
    print("\nëŒ€í™”í˜• ëª¨ë“œ (ì¢…ë£Œí•˜ë ¤ë©´ 'quit' ë˜ëŠ” 'exit' ì…ë ¥)")
    print("="*60 + "\n")
    
    while True:
        user_query = input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”: ").strip()
        
        # ì¢…ë£Œ ëª…ë ¹ì–´ í™•ì¸
        if user_query.lower() in ['quit', 'exit', 'ì¢…ë£Œ']:
            print("\ní”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        
        # ë¹ˆ ì…ë ¥ ë¬´ì‹œ
        if not user_query:
            continue
        
        # ì§ˆë¬¸ ì²˜ë¦¬
        search_and_answer(rag_chain, retriever, user_query)


if __name__ == "__main__":
    main()