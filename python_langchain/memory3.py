import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import HumanMessage, AIMessage

load_dotenv()

# 1. ëª¨ë¸ ì„¤ì •
llm = ChatOpenAI(model="gpt-4o", streaming=True)

# 2. í”„ë¡¬í”„íŠ¸ ì„¤ì • (ê¸°ì–µ ë³´ê´€í•¨ í¬í•¨)
prompt = ChatPromptTemplate.from_messages([
    ("system", "ë„ˆëŠ” ë…ì„œ ìŠµê´€ì„ ë„ì™€ì£¼ëŠ” ì¹œì ˆí•œ ë…ì„œ ì½”ì¹˜ì•¼. ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ êµ¬ì²´ì ì¸ ê³„íšì„ ì„¸ì›Œì¤˜."),
    MessagesPlaceholder(variable_name="chat_history"),
    ("user", "{input}")
])

# 3. ì²´ì¸ ìƒì„±
chain = prompt | llm

# 4. ì‹œë®¬ë ˆì´ì…˜í•  ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸
questions = [
    "ë‚´ê°€ ì•„ê¹Œ ì¶”ì²œí•´ë‹¬ë¼ê³  í•œ ì±…ë“¤ì€ ë¬´ì—‡ì´ì—ˆì§€?",
    "ì„œìš¸ì˜ ì¸êµ¬ëŠ” 2025ë…„ ê¸°ì¤€ ëª‡ ëª…?"
]

# 5. ëŒ€í™” ê¸°ë¡ ì €ì¥ì†Œ
history = []

print("=== ğŸ“– ë…ì„œ ì½”ì¹˜ ì—°ì† ëŒ€í™” ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘ ===\n")

for q in questions:
    print(f"ë‚˜: {q}")
    
    # AI ë‹µë³€ ìƒì„± (ì§€ê¸ˆê¹Œì§€ì˜ ê¸°ë¡ historyë¥¼ ê°™ì´ ë³´ëƒ„)
    response = chain.invoke({
        "input": q,
        "chat_history": history
    })
    
    print(f"AI: {response.content}")
    print("-" * 30)
    
    # ëŒ€í™” ê¸°ë¡ ì—…ë°ì´íŠ¸ (ì´ê²Œ ìˆì–´ì•¼ ë‹¤ìŒ ì§ˆë¬¸ì—ì„œ ê¸°ì–µì„ í•¨!)
    history.append(HumanMessage(content=q))
    history.append(AIMessage(content=response.content))
 
print("\n=== ì‹œë®¬ë ˆì´ì…˜ ì¢…ë£Œ ===")

# k ê°’ = ìµœê·¼ ëª‡ í„´ì˜ ëŒ€í™”ë¥¼ ìœ ì§€í• ì§€ ê²°ì •
# k=3: ìµœê·¼ 3í„´ì˜ ëŒ€í™”ë§Œ ìœ ì§€ (ì‚¬ìš©ì ì§ˆë¬¸ + AI ì‘ë‹µì„ 1í„´ìœ¼ë¡œ ê³„ì‚°)
# ì˜¤ë˜ëœ ëŒ€í™”ëŠ” ìë™ìœ¼ë¡œ ì‚­ì œë¨

# ê¶Œì¥ k ê°’:
# k=2~3: ê°„ë‹¨í•œ FAQ, ë‹¨ìˆœ ì§ˆì˜ì‘ë‹µ
# k=5 â­ï¸: ê°€ì¥ ì¼ë°˜ì , ì‹œì‘ ê¸°ë³¸ê°’ìœ¼ë¡œ ì¶”ì²œ
# k=7~10: ìƒë‹´, êµìœ¡, ì½”ë”© ë„ìš°ë¯¸
# k=10~15: ë³µì¡í•œ ë¬¸ì œ í•´ê²°, ì¥í¸ ì‘ì—…
# k=20+: ë§¤ìš° íŠ¹ìˆ˜í•œ ê²½ìš° (ë¹„ìš© ë¶€ë‹´ í¼)