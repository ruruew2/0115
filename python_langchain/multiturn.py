import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import HumanMessage, AIMessage

load_dotenv()

# 1. ëª¨ë¸ ì„¤ì •
llm = ChatOpenAI(model="gpt-4.0", temperature=0.8)

# 2. ë©€í‹°í„´ìš© í”„ë¡¬í”„íŠ¸ ì„¤ì • (MessagesPlaceholderê°€ í•µì‹¬!)
prompt = ChatPromptTemplate.from_messages([
    ("system", "ë„ˆëŠ” ì—´ì •ì ì¸ ë¯¸ìŠë­ ì…°í”„ì•¼. ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ê¸°ì–µí•´ì„œ ì†ë‹˜ê³¼ í‹°í‚¤íƒ€ì¹´ ëŒ€í™”ë¥¼ ë‚˜ëˆ ì¤˜."),
    MessagesPlaceholder(variable_name="chat_history"), # ì´ ìë¦¬ì— ëŒ€í™” ê¸°ë¡ì´ ë“¤ì–´ê°
    ("user", "{input}")
])

# 3. ì²´ì¸ ìƒì„±
chain = prompt | llm   

# 4. ëŒ€í™” ê¸°ë¡ì„ ë‹´ì„ ë°”êµ¬ë‹ˆ (ë©”ëª¨ë¦¬)
history = []

print("=== ğŸ‘¨â€ğŸ³ ì…°í”„ì™€ì˜ 1:1 ëŒ€í™” (ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ì…ë ¥) ===")

while True:
    user_input = input("ë‚˜: ")
    if user_input.lower() == 'exit':
        break

    # AIì˜ ë‹µë³€ ìƒì„± (ê¸°ì¡´ ëŒ€í™” ê¸°ë¡ì¸ historyë¥¼ í•¨ê»˜ ì „ë‹¬)
    response = chain.invoke({
        "input": user_input,
        "chat_history": history
    })

    print(f"ì…°í”„: {response.content}")

    # 5. ëŒ€í™” ê¸°ë¡ ì—…ë°ì´íŠ¸ (ë‚˜ì˜ ì§ˆë¬¸ê³¼ AIì˜ ë‹µë³€ì„ ì €ì¥)
    history.append(HumanMessage(content=user_input))
    history.append(AIMessage(content=response.content))

    # (ì„ íƒ) ê¸°ë¡ì´ ë„ˆë¬´ ê¸¸ì–´ì§€ë©´ ì•ë¶€ë¶„ì„ ìë¥´ê¸°ë„ í•˜ì§€ë§Œ, ì¼ë‹¨ì€ ë‹¤ ì €ì¥í•©ë‹ˆë‹¤!