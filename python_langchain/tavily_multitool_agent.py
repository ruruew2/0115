"""
ë‹¤ì¤‘ ë„êµ¬ Agent - TAVILY ê²€ìƒ‰ + Python ê³„ì‚°ê¸°
ì—¬ëŸ¬ ë„êµ¬ ì¤‘ ìƒí™©ì— ë§ëŠ” ë„êµ¬ë¥¼ ì„ íƒí•˜ê³  ì¡°í•©í•˜ëŠ” Agent ì˜ˆì œ
"""

# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.messages import HumanMessage, SystemMessage, ToolMessage
from langchain_core.tools import tool

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()


# ì»¤ìŠ¤í…€ ë„êµ¬ ì •ì˜: Python ê³„ì‚°ê¸°
@tool
def python_calculator(expression: str) -> str:
    """Python í‘œí˜„ì‹ì„ ì•ˆì „í•˜ê²Œ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    ì‚¬ìš© ì˜ˆì‹œ:
    - "100 * 2" â†’ 200
    - "(500 - 100) / 100 * 100" â†’ 400.0
    - "pow(2, 10)" â†’ 1024
    
    Args:
        expression: ê³„ì‚°í•  Python í‘œí˜„ì‹ (ë¬¸ìì—´)
    
    Returns:
        ê³„ì‚° ê²°ê³¼ (ë¬¸ìì—´)
    """
    try:
        # ì•ˆì „í•œ ìˆ˜í•™ ì—°ì‚°ë§Œ í—ˆìš© (eval ëŒ€ì‹  ì œí•œëœ í™˜ê²½ ì‚¬ìš©)
        allowed_names = {
            'abs': abs, 'round': round, 'min': min, 'max': max,
            'sum': sum, 'pow': pow, 'len': len,
        }
        
        # evalì„ ì•ˆì „í•˜ê²Œ ì‚¬ìš© (ì œí•œëœ í•¨ìˆ˜ë§Œ í—ˆìš©)
        result = eval(expression, {"__builtins__": {}}, allowed_names)
      # {"__builtins__": {}} : ì•„ë¬´ëŸ° ê¸°ë³¸ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ë„ë¡ ê°•ì œë¡œ ì°¨ë‹¨
        return str(result)
    except Exception as e:
        return f"ê³„ì‚° ì˜¤ë¥˜: {str(e)}"


def main():
    """ë‹¤ì¤‘ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ëŠ” Agent êµ¬í˜„ ë° ì‹¤í–‰"""
    
    # API í‚¤ ë¡œë“œ
    openai_api_key = os.getenv("OPENAI_API_KEY")
    tavily_api_key = os.getenv("TAVILY_API_KEY")
    
    if not openai_api_key or not tavily_api_key:
        print(" # API í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return
    
    print(" # API í‚¤ ë¡œë“œ ì™„ë£Œ\n")
    
    # 1. LLM ëª¨ë¸ ì´ˆê¸°í™”
    llm = ChatOpenAI(
        model="gpt-4o-mini",
        temperature=0,
        api_key=openai_api_key
    )
    print(" # OpenAI LLM ì´ˆê¸°í™” ì™„ë£Œ")
    
    # 2. ë„êµ¬ë“¤ ì„¤ì •
    # 2-1. TAVILY ê²€ìƒ‰ ë„êµ¬
    search_tool = TavilySearchResults(
        max_results=3,
        search_depth="advanced",
        include_answer=True,
        include_raw_content=False,
        include_images=False,
        api_key=tavily_api_key
    )
    
    # 2-2. Python ê³„ì‚°ê¸° ë„êµ¬
    calculator = python_calculator
    
    # ëª¨ë“  ë„êµ¬ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ê´€ë¦¬
    tools_list = [search_tool, calculator]
    
    # ë„êµ¬ ë”•ì…”ë„ˆë¦¬ (ë„êµ¬ ì´ë¦„ìœ¼ë¡œ ë¹ ë¥´ê²Œ ì°¾ê¸° ìœ„í•¨)
    tools = {
        "tavily_search_results_json": search_tool,
        "python_calculator": calculator,
    }
    
    print(" # ë„êµ¬ ì„¤ì • ì™„ë£Œ:")
    print("   - TAVILY ê²€ìƒ‰ ë„êµ¬")
    print("   - Python ê³„ì‚°ê¸° ë„êµ¬")
    
    # 3. LLMì— ëª¨ë“  ë„êµ¬ ë°”ì¸ë”©
    llm_with_tools = llm.bind_tools(tools_list)
    print(" # Agent ì´ˆê¸°í™” ì™„ë£Œ (2ê°œ ë„êµ¬ ë°”ì¸ë”©)\n")
    
    # 4. ë‹¤ì¤‘ ë„êµ¬ ì¡°í•©ì´ í•„ìš”í•œ ë³µì¡í•œ ì§ˆë¬¸ ì‹¤í–‰
    questions = [
        "2025ë…„ ë¹„íŠ¸ì½”ì¸ ìµœê³ ê°€ì™€ 2020ë…„ ë¹„íŠ¸ì½”ì¸ í‰ê·  ê°€ê²©ì„ ë¹„êµí•´ì„œ, ëª‡ í¼ì„¼íŠ¸ ìƒìŠ¹í–ˆëŠ”ì§€ ê³„ì‚°í•´ì¤˜",
        "2025ë…„ ë¡¤ë“œì»µ ìš°ìŠ¹íŒ€ì˜ ìš°ìŠ¹ íšŸìˆ˜ì™€ ì¤€ìš°ìŠ¹íŒ€ì˜ ìš°ìŠ¹ íšŸìˆ˜ë¥¼ ë”í•˜ë©´?",
        "ë‹¨ìˆœ ê³„ì‚°: 1234 ê³±í•˜ê¸° 5678ì€?",
    ]
    
    for question in questions:
        print(f"\n{'='*70}")
        print(f"ì§ˆë¬¸: {question}")
        print(f"{'='*70}\n")
        
        run_multi_tool_agent(question, llm, llm_with_tools, tools, max_iterations=7)
        print("\n" + "="*70 + "\n")


def run_multi_tool_agent(question, llm, llm_with_tools, tools, max_iterations=7):
    """ë‹¤ì¤‘ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ëŠ” Agent ë°˜ë³µ ì¶”ë¡  ë£¨í”„
    
    ì´ í•¨ìˆ˜ëŠ” ì—¬ëŸ¬ ë„êµ¬ ì¤‘ ìƒí™©ì— ë§ëŠ” ë„êµ¬ë¥¼ ì„ íƒí•˜ê³  ì¡°í•©í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
    
    Args:
        question (str): ì‚¬ìš©ì ì§ˆë¬¸
        llm (ChatOpenAI): ê¸°ë³¸ LLM
        llm_with_tools (ChatOpenAI): ë„êµ¬ê°€ ë°”ì¸ë”©ëœ LLM
        tools (dict): ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ë”•ì…”ë„ˆë¦¬
        max_iterations (int): ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜
    """
    
    # ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
    messages = [
        SystemMessage(content="""ë‹¹ì‹ ì€ ê²€ìƒ‰ê³¼ ê³„ì‚°ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” AI Agentì…ë‹ˆë‹¤.

        ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬:
        1. tavily_search_results_json: ìµœì‹  ì •ë³´ë¥¼ ì›¹ì—ì„œ ê²€ìƒ‰í•©ë‹ˆë‹¤.
        2. python_calculator: ìˆ˜í•™ ê³„ì‚°ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

        ì£¼ìš” ì—­í• :
        - ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ í•„ìš”í•œ ë„êµ¬ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.
        - ê²€ìƒ‰ì´ í•„ìš”í•˜ë©´ ê²€ìƒ‰ ë„êµ¬ë¥¼, ê³„ì‚°ì´ í•„ìš”í•˜ë©´ ê³„ì‚°ê¸°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
        - ì—¬ëŸ¬ ë„êµ¬ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì¡°í•©í•˜ì—¬ ë³µì¡í•œ ë¬¸ì œë¥¼ í•´ê²°í•©ë‹ˆë‹¤.
        - í•œêµ­ì–´ë¡œ ë‹µë³€í•©ë‹ˆë‹¤.

        ë„êµ¬ ì‚¬ìš© ì „ëµ:
        - ìµœì‹  ì •ë³´ë‚˜ ì‹¤ì‹œê°„ ë°ì´í„°ê°€ í•„ìš”í•˜ë©´ ê²€ìƒ‰ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
        - ìˆ«ì ê³„ì‚°ì´ í•„ìš”í•˜ë©´ ê³„ì‚°ê¸° ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
        - ê²€ìƒ‰ ê²°ê³¼ì˜ ìˆ«ìë¥¼ ê³„ì‚°í•´ì•¼ í•œë‹¤ë©´ ê²€ìƒ‰ í›„ ê³„ì‚°ê¸°ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
        - í•œ ë²ˆì— í•˜ë‚˜ì”© ë‹¨ê³„ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ì„¸ìš”.
        - ì¶©ë¶„í•œ ì •ë³´ì™€ ê³„ì‚°ì´ ì™„ë£Œë˜ë©´ ìµœì¢… ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”."""),
        HumanMessage(content=question)
    ]
    
    # ë°˜ë³µ ì¶”ë¡  ë£¨í”„
    for iteration in range(max_iterations):
        print(f"\n[Iteration {iteration + 1}/{max_iterations}]")
        print("-" * 70)
        
        # Step 1: LLMì—ê²Œ ë‹¤ìŒ í–‰ë™ ê²°ì • ìš”ì²­
        ai_msg = llm_with_tools.invoke(messages)
        messages.append(ai_msg)
        
        # Step 2: ë„êµ¬ í˜¸ì¶œì´ ìˆëŠ”ì§€ í™•ì¸
        if hasattr(ai_msg, 'tool_calls') and ai_msg.tool_calls:
            print(f"ğŸ”§ Agent íŒë‹¨: ë„êµ¬ ì‚¬ìš© í•„ìš” ({len(ai_msg.tool_calls)}ê°œ ë„êµ¬ í˜¸ì¶œ)")
            
            # Step 3: ê° ë„êµ¬ í˜¸ì¶œ ì‹¤í–‰
            for tool_call in ai_msg.tool_calls:
                tool_name = tool_call['name']
                tool_args = tool_call['args']
                
                print(f"\n   # ì„ íƒëœ ë„êµ¬: {tool_name}")
                
                # ë„êµ¬ë³„ë¡œ ë‹¤ë¥¸ ì •ë³´ ì¶œë ¥
                if tool_name == "tavily_search_results_json":
                    print(f"  ğŸ“ ê²€ìƒ‰ì–´: {tool_args.get('query', 'N/A')}")
                elif tool_name == "python_calculator":
                    print(f"  ğŸ§® ê³„ì‚°ì‹: {tool_args.get('expression', 'N/A')}")
                else:
                    print(f"  ğŸ“ ì¸ì: {tool_args}")
                
                # ë„êµ¬ ì‹¤í–‰
                if tool_name in tools:
                    try:
                        tool_output = tools[tool_name].invoke(tool_args)
                        
                        # ê²°ê³¼ ìš”ì•½ ì¶œë ¥
                        if tool_name == "tavily_search_results_json":
                            print(f"   # ê²€ìƒ‰ ì™„ë£Œ: {len(tool_output)}ê°œ ê²°ê³¼")
                            if tool_output:
                                first_result = tool_output[0].get('content', '')[:80]
                                print(f"     ì²« ê²°ê³¼: {first_result}...")
                        elif tool_name == "python_calculator":
                            print(f"   # ê³„ì‚° ê²°ê³¼: {tool_output}")
                        else:
                            print(f"   # ì‹¤í–‰ ì™„ë£Œ")
                        
                        # ë„êµ¬ ê²°ê³¼ë¥¼ ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
                        messages.append(
                            ToolMessage(
                                content=str(tool_output),
                                tool_call_id=tool_call['id']
                            )
                        )
                    except Exception as e:
                        print(f"   # ë„êµ¬ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}")
                        messages.append(
                            ToolMessage(
                                content=f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                                tool_call_id=tool_call['id']
                            )
                        )
                else:
                    print(f"   # ì•Œ ìˆ˜ ì—†ëŠ” ë„êµ¬: {tool_name}")
            
            print(f"\n  ğŸ’­ Agentê°€ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ë¶„ì„ ì¤‘...")
            
        else:
            # Step 4: ë„êµ¬ í˜¸ì¶œ ì—†ìŒ = ìµœì¢… ë‹µë³€
            print(" # Agent íŒë‹¨: ì¶©ë¶„í•œ ì •ë³´ ìˆ˜ì§‘ ë° ê³„ì‚° ì™„ë£Œ, ìµœì¢… ë‹µë³€ ìƒì„±")
            print("\n" + "="*70)
            print(" # ìµœì¢… ë‹µë³€:")
            print("="*70)
            print(ai_msg.content)
            print("="*70)
            
            return
    
    # ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ ë„ë‹¬
    print(f"\n  # ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜({max_iterations})ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤.")
    print("ë§ˆì§€ë§‰ ìƒíƒœë¡œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.\n")
    
    final_msg = llm.invoke(messages + [
        HumanMessage(content="ì§€ê¸ˆê¹Œì§€ ìˆ˜ì§‘í•˜ê³  ê³„ì‚°í•œ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ë‹µë³€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.")
    ])
    
    print("="*70)
    print(" # ìµœì¢… ë‹µë³€ (ê°•ì œ):")
    print("="*70)
    print(final_msg.content)
    print("="*70)


if __name__ == "__main__":
    main()
